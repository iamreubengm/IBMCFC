# IBM Call For Code 2020 

See(k) Help : An App For The Blind And Visually Impaired.

## Steps to Run the Project:

**First, install dependencies mentioned in requirements.txt**

> pip install -r requirements.txt



1. Download both 'inception' and 'prediction.h5' from [here](https://drive.google.com/drive/folders/1xSfaPYT7tZAN9sQZovjkeVF8jvLzmOSo) and place them in 'models' directory.
2. Open homex.html (located in the 'run' folder) in a browser.
3. Open the text files located in 'api' folder and enter the required api keys and urls for the IBM services. Note : API keys are already included but suggested to be changed by the user during the time of running the project.
4. Run test_req.py and wait for it to deploy
5. Choose language of choice and the image to be checked.
6. After clicking on 'listen' wait for 5-10 seconds for the audio to play on the webpage.

### Training the model : All training files has been included in the 'models_to_train' folder, with inspiration from [Harshall Lamba](https://github.com/hlamba28/Automatic-Image-Captioning/blob/master/Automatic%20Image%20Captioning.ipynb)
